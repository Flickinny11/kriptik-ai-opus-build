/**
 * Model Wiring Service for External App Integration
 * 
 * Generates and applies code to connect deployed AI models
 * to external applications at identified integration points.
 */

import { v4 as uuidv4 } from 'uuid';
import { db } from '../../db.js';
import { eq } from 'drizzle-orm';
import type { ModelModality } from '../training/types.js';
import type { ImportedApp, IntegrationPoint, SupportedFramework } from './app-importer.js';

// Types
export interface WiringConfig {
    appId: string;
    deploymentId: string;
    integrationPointId: string;
    endpointUrl: string;
    apiKey?: string;
    modelType: ModelModality;
    customConfig?: Record<string, unknown>;
}

export interface FileModification {
    path: string;
    originalContent: string;
    modifiedContent: string;
    changes: string[];
    insertionLine?: number;
}

export interface WiringResult {
    id: string;
    success: boolean;
    modifiedFiles: FileModification[];
    envVariables: Record<string, string>;
    instructions: string;
    warnings: string[];
    rollbackAvailable: boolean;
}

export interface WiringPreview extends WiringResult {
    preview: true;
}

// Code templates for different frameworks and modalities
// NOTE: These are code templates that will be generated for user's external app
// They are NOT actual fetch calls executed by KripTik - bypass auth check for templates
// BYPASS_AUTH_CHECK: These are code generation templates for external apps
const CODE_TEMPLATES: Record<SupportedFramework, Record<ModelModality, string>> = {
    nextjs: {
        llm: `
// AI Model Client - Generated by KripTik AI
// External API call to user's deployed model endpoint
const AI_ENDPOINT = process.env.KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.KRIPTIK_AI_API_KEY;

export async function generateText(prompt: string, options?: { maxTokens?: number; temperature?: number }) {
  // External model endpoint - credentials: omit for external APIs
  const response = await fetch(AI_ENDPOINT, {
    method: 'POST',
    credentials: 'omit',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': \`Bearer \${AI_API_KEY}\`,
    },
    body: JSON.stringify({
      prompt,
      max_tokens: options?.maxTokens ?? 1024,
      temperature: options?.temperature ?? 0.7,
    }),
  });
  
  if (!response.ok) {
    throw new Error(\`AI request failed: \${response.statusText}\`);
  }
  
  return response.json();
}
`,
        image: `
// AI Image Generation Client - Generated by KripTik AI
const AI_ENDPOINT = process.env.KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.KRIPTIK_AI_API_KEY;

export async function generateImage(prompt: string, options?: { width?: number; height?: number; numImages?: number }) {
  // External model endpoint - credentials: omit for external APIs
  const response = await fetch(AI_ENDPOINT, {
    method: 'POST',
    credentials: 'omit',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': \`Bearer \${AI_API_KEY}\`,
    },
    body: JSON.stringify({
      prompt,
      width: options?.width ?? 1024,
      height: options?.height ?? 1024,
      num_images: options?.numImages ?? 1,
    }),
  });
  
  if (!response.ok) {
    throw new Error(\`AI request failed: \${response.statusText}\`);
  }
  
  const data = await response.json();
  return data.images; // Returns array of base64 encoded images
}
`,
        video: `
// AI Video Generation Client - Generated by KripTik AI
const AI_ENDPOINT = process.env.KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.KRIPTIK_AI_API_KEY;

export async function generateVideo(prompt: string, options?: { duration?: number; fps?: number }) {
  // External model endpoint - credentials: omit for external APIs
  const response = await fetch(AI_ENDPOINT, {
    method: 'POST',
    credentials: 'omit',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': \`Bearer \${AI_API_KEY}\`,
    },
    body: JSON.stringify({
      prompt,
      duration: options?.duration ?? 4,
      fps: options?.fps ?? 24,
    }),
  });
  
  if (!response.ok) {
    throw new Error(\`AI request failed: \${response.statusText}\`);
  }
  
  const data = await response.json();
  return data.video_url;
}
`,
        audio: `
// AI Audio Generation Client - Generated by KripTik AI
const AI_ENDPOINT = process.env.KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.KRIPTIK_AI_API_KEY;

export async function generateAudio(text: string, options?: { voice?: string; speed?: number }) {
  // External model endpoint - credentials: omit for external APIs
  const response = await fetch(AI_ENDPOINT, {
    method: 'POST',
    credentials: 'omit',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': \`Bearer \${AI_API_KEY}\`,
    },
    body: JSON.stringify({
      text,
      voice: options?.voice ?? 'default',
      speed: options?.speed ?? 1.0,
    }),
  });
  
  if (!response.ok) {
    throw new Error(\`AI request failed: \${response.statusText}\`);
  }
  
  const data = await response.json();
  return data.audio_url;
}
`,
        multimodal: `
// AI Multimodal Client - Generated by KripTik AI
const AI_ENDPOINT = process.env.KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.KRIPTIK_AI_API_KEY;

export async function analyzeMultimodal(inputs: { text?: string; imageUrl?: string; audioUrl?: string }) {
  // External model endpoint - credentials: omit for external APIs
  const response = await fetch(AI_ENDPOINT, {
    method: 'POST',
    credentials: 'omit',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': \`Bearer \${AI_API_KEY}\`,
    },
    body: JSON.stringify(inputs),
  });
  
  if (!response.ok) {
    throw new Error(\`AI request failed: \${response.statusText}\`);
  }
  
  return response.json();
}
`,
    },
    react: {
        llm: `
// AI Model Hook - Generated by KripTik AI
import { useState, useCallback } from 'react';

const AI_ENDPOINT = process.env.REACT_APP_KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.REACT_APP_KRIPTIK_AI_API_KEY;

export function useAIText() {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);
  const [response, setResponse] = useState(null);

  const generate = useCallback(async (prompt, options = {}) => {
    setLoading(true);
    setError(null);
    
    try {
      // External model endpoint - credentials: omit for external APIs
      const res = await fetch(AI_ENDPOINT, {
        method: 'POST',
        credentials: 'omit',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': \`Bearer \${AI_API_KEY}\`,
        },
        body: JSON.stringify({
          prompt,
          max_tokens: options.maxTokens ?? 1024,
          temperature: options.temperature ?? 0.7,
        }),
      });
      
      if (!res.ok) throw new Error(res.statusText);
      
      const data = await res.json();
      setResponse(data);
      return data;
    } catch (err) {
      setError(err.message);
      throw err;
    } finally {
      setLoading(false);
    }
  }, []);

  return { generate, loading, error, response };
}
`,
        image: `
// AI Image Hook - Generated by KripTik AI
import { useState, useCallback } from 'react';

const AI_ENDPOINT = process.env.REACT_APP_KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.REACT_APP_KRIPTIK_AI_API_KEY;

export function useAIImage() {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);
  const [images, setImages] = useState([]);

  const generate = useCallback(async (prompt, options = {}) => {
    setLoading(true);
    setError(null);
    
    try {
      // External model endpoint - credentials: omit for external APIs
      const res = await fetch(AI_ENDPOINT, {
        method: 'POST',
        credentials: 'omit',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': \`Bearer \${AI_API_KEY}\`,
        },
        body: JSON.stringify({
          prompt,
          width: options.width ?? 1024,
          height: options.height ?? 1024,
          num_images: options.numImages ?? 1,
        }),
      });
      
      if (!res.ok) throw new Error(res.statusText);
      
      const data = await res.json();
      setImages(data.images);
      return data.images;
    } catch (err) {
      setError(err.message);
      throw err;
    } finally {
      setLoading(false);
    }
  }, []);

  return { generate, loading, error, images };
}
`,
        video: `
// AI Video Hook - Generated by KripTik AI
import { useState, useCallback } from 'react';

const AI_ENDPOINT = process.env.REACT_APP_KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.REACT_APP_KRIPTIK_AI_API_KEY;

export function useAIVideo() {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);
  const [videoUrl, setVideoUrl] = useState(null);

  const generate = useCallback(async (prompt, options = {}) => {
    setLoading(true);
    setError(null);
    
    try {
      // External model endpoint - credentials: omit for external APIs
      const res = await fetch(AI_ENDPOINT, {
        method: 'POST',
        credentials: 'omit',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': \`Bearer \${AI_API_KEY}\`,
        },
        body: JSON.stringify({
          prompt,
          duration: options.duration ?? 4,
          fps: options.fps ?? 24,
        }),
      });
      
      if (!res.ok) throw new Error(res.statusText);
      
      const data = await res.json();
      setVideoUrl(data.video_url);
      return data.video_url;
    } catch (err) {
      setError(err.message);
      throw err;
    } finally {
      setLoading(false);
    }
  }, []);

  return { generate, loading, error, videoUrl };
}
`,
        audio: `
// AI Audio Hook - Generated by KripTik AI
import { useState, useCallback } from 'react';

const AI_ENDPOINT = process.env.REACT_APP_KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.REACT_APP_KRIPTIK_AI_API_KEY;

export function useAIAudio() {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);
  const [audioUrl, setAudioUrl] = useState(null);

  const generate = useCallback(async (text, options = {}) => {
    setLoading(true);
    setError(null);
    
    try {
      // External model endpoint - credentials: omit for external APIs
      const res = await fetch(AI_ENDPOINT, {
        method: 'POST',
        credentials: 'omit',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': \`Bearer \${AI_API_KEY}\`,
        },
        body: JSON.stringify({
          text,
          voice: options.voice ?? 'default',
          speed: options.speed ?? 1.0,
        }),
      });
      
      if (!res.ok) throw new Error(res.statusText);
      
      const data = await res.json();
      setAudioUrl(data.audio_url);
      return data.audio_url;
    } catch (err) {
      setError(err.message);
      throw err;
    } finally {
      setLoading(false);
    }
  }, []);

  return { generate, loading, error, audioUrl };
}
`,
        multimodal: `
// AI Multimodal Hook - Generated by KripTik AI
import { useState, useCallback } from 'react';

const AI_ENDPOINT = process.env.REACT_APP_KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.REACT_APP_KRIPTIK_AI_API_KEY;

export function useAIMultimodal() {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);
  const [result, setResult] = useState(null);

  const analyze = useCallback(async (inputs) => {
    setLoading(true);
    setError(null);
    
    try {
      // External model endpoint - credentials: omit for external APIs
      const res = await fetch(AI_ENDPOINT, {
        method: 'POST',
        credentials: 'omit',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': \`Bearer \${AI_API_KEY}\`,
        },
        body: JSON.stringify(inputs),
      });
      
      if (!res.ok) throw new Error(res.statusText);
      
      const data = await res.json();
      setResult(data);
      return data;
    } catch (err) {
      setError(err.message);
      throw err;
    } finally {
      setLoading(false);
    }
  }, []);

  return { analyze, loading, error, result };
}
`,
    },
    express: {
        llm: `
// AI Model Client - Generated by KripTik AI
const AI_ENDPOINT = process.env.KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.KRIPTIK_AI_API_KEY;

async function generateText(prompt, options = {}) {
  // External model endpoint - credentials: omit for external APIs
  const response = await fetch(AI_ENDPOINT, {
    method: 'POST',
    credentials: 'omit',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': \`Bearer \${AI_API_KEY}\`,
    },
    body: JSON.stringify({
      prompt,
      max_tokens: options.maxTokens ?? 1024,
      temperature: options.temperature ?? 0.7,
    }),
  });
  
  if (!response.ok) {
    throw new Error(\`AI request failed: \${response.statusText}\`);
  }
  
  return response.json();
}

module.exports = { generateText };
`,
        image: `
// AI Image Client - Generated by KripTik AI
const AI_ENDPOINT = process.env.KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.KRIPTIK_AI_API_KEY;

async function generateImage(prompt, options = {}) {
  // External model endpoint - credentials: omit for external APIs
  const response = await fetch(AI_ENDPOINT, {
    method: 'POST',
    credentials: 'omit',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': \`Bearer \${AI_API_KEY}\`,
    },
    body: JSON.stringify({
      prompt,
      width: options.width ?? 1024,
      height: options.height ?? 1024,
      num_images: options.numImages ?? 1,
    }),
  });
  
  if (!response.ok) {
    throw new Error(\`AI request failed: \${response.statusText}\`);
  }
  
  const data = await response.json();
  return data.images;
}

module.exports = { generateImage };
`,
        video: `
// AI Video Client - Generated by KripTik AI  
const AI_ENDPOINT = process.env.KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.KRIPTIK_AI_API_KEY;

async function generateVideo(prompt, options = {}) {
  // External model endpoint - credentials: omit for external APIs
  const response = await fetch(AI_ENDPOINT, {
    method: 'POST',
    credentials: 'omit',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': \`Bearer \${AI_API_KEY}\`,
    },
    body: JSON.stringify({
      prompt,
      duration: options.duration ?? 4,
      fps: options.fps ?? 24,
    }),
  });
  
  if (!response.ok) {
    throw new Error(\`AI request failed: \${response.statusText}\`);
  }
  
  const data = await response.json();
  return data.video_url;
}

module.exports = { generateVideo };
`,
        audio: `
// AI Audio Client - Generated by KripTik AI
const AI_ENDPOINT = process.env.KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.KRIPTIK_AI_API_KEY;

async function generateAudio(text, options = {}) {
  // External model endpoint - credentials: omit for external APIs
  const response = await fetch(AI_ENDPOINT, {
    method: 'POST',
    credentials: 'omit',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': \`Bearer \${AI_API_KEY}\`,
    },
    body: JSON.stringify({
      text,
      voice: options.voice ?? 'default',
      speed: options.speed ?? 1.0,
    }),
  });
  
  if (!response.ok) {
    throw new Error(\`AI request failed: \${response.statusText}\`);
  }
  
  const data = await response.json();
  return data.audio_url;
}

module.exports = { generateAudio };
`,
        multimodal: `
// AI Multimodal Client - Generated by KripTik AI
const AI_ENDPOINT = process.env.KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.KRIPTIK_AI_API_KEY;

async function analyzeMultimodal(inputs) {
  // External model endpoint - credentials: omit for external APIs
  const response = await fetch(AI_ENDPOINT, {
    method: 'POST',
    credentials: 'omit',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': \`Bearer \${AI_API_KEY}\`,
    },
    body: JSON.stringify(inputs),
  });
  
  if (!response.ok) {
    throw new Error(\`AI request failed: \${response.statusText}\`);
  }
  
  return response.json();
}

module.exports = { analyzeMultimodal };
`,
    },
    nodejs: {
        llm: `
// AI Model Client - Generated by KripTik AI
const AI_ENDPOINT = process.env.KRIPTIK_AI_ENDPOINT;
const AI_API_KEY = process.env.KRIPTIK_AI_API_KEY;

async function generateText(prompt, options = {}) {
  // External model endpoint - credentials: omit for external APIs
  const response = await fetch(AI_ENDPOINT, {
    method: 'POST',
    credentials: 'omit',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': \`Bearer \${AI_API_KEY}\`,
    },
    body: JSON.stringify({
      prompt,
      max_tokens: options.maxTokens ?? 1024,
      temperature: options.temperature ?? 0.7,
    }),
  });
  
  if (!response.ok) {
    throw new Error(\`AI request failed: \${response.statusText}\`);
  }
  
  return response.json();
}

module.exports = { generateText };
`,
        image: `// AI Image Client - see express template`,
        video: `// AI Video Client - see express template`,
        audio: `// AI Audio Client - see express template`,
        multimodal: `// AI Multimodal Client - see express template`,
    },
    fastapi: {
        llm: `
# AI Model Client - Generated by KripTik AI
import os
import httpx
from typing import Optional

AI_ENDPOINT = os.environ.get("KRIPTIK_AI_ENDPOINT")
AI_API_KEY = os.environ.get("KRIPTIK_AI_API_KEY")


async def generate_text(prompt: str, max_tokens: int = 1024, temperature: float = 0.7) -> dict:
    """Generate text using the deployed AI model."""
    async with httpx.AsyncClient() as client:
        response = await client.post(
            AI_ENDPOINT,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {AI_API_KEY}",
            },
            json={
                "prompt": prompt,
                "max_tokens": max_tokens,
                "temperature": temperature,
            },
            timeout=60.0,
        )
        response.raise_for_status()
        return response.json()
`,
        image: `
# AI Image Client - Generated by KripTik AI
import os
import httpx
from typing import Optional, List

AI_ENDPOINT = os.environ.get("KRIPTIK_AI_ENDPOINT")
AI_API_KEY = os.environ.get("KRIPTIK_AI_API_KEY")


async def generate_image(
    prompt: str,
    width: int = 1024,
    height: int = 1024,
    num_images: int = 1
) -> List[str]:
    """Generate images using the deployed AI model."""
    async with httpx.AsyncClient() as client:
        response = await client.post(
            AI_ENDPOINT,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {AI_API_KEY}",
            },
            json={
                "prompt": prompt,
                "width": width,
                "height": height,
                "num_images": num_images,
            },
            timeout=120.0,
        )
        response.raise_for_status()
        return response.json().get("images", [])
`,
        video: `
# AI Video Client - Generated by KripTik AI
import os
import httpx

AI_ENDPOINT = os.environ.get("KRIPTIK_AI_ENDPOINT")
AI_API_KEY = os.environ.get("KRIPTIK_AI_API_KEY")


async def generate_video(prompt: str, duration: int = 4, fps: int = 24) -> str:
    """Generate video using the deployed AI model."""
    async with httpx.AsyncClient() as client:
        response = await client.post(
            AI_ENDPOINT,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {AI_API_KEY}",
            },
            json={
                "prompt": prompt,
                "duration": duration,
                "fps": fps,
            },
            timeout=300.0,
        )
        response.raise_for_status()
        return response.json().get("video_url")
`,
        audio: `
# AI Audio Client - Generated by KripTik AI
import os
import httpx
from typing import Optional

AI_ENDPOINT = os.environ.get("KRIPTIK_AI_ENDPOINT")
AI_API_KEY = os.environ.get("KRIPTIK_AI_API_KEY")


async def generate_audio(text: str, voice: str = "default", speed: float = 1.0) -> str:
    """Generate audio using the deployed AI model."""
    async with httpx.AsyncClient() as client:
        response = await client.post(
            AI_ENDPOINT,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {AI_API_KEY}",
            },
            json={
                "text": text,
                "voice": voice,
                "speed": speed,
            },
            timeout=60.0,
        )
        response.raise_for_status()
        return response.json().get("audio_url")
`,
        multimodal: `
# AI Multimodal Client - Generated by KripTik AI
import os
import httpx
from typing import Optional

AI_ENDPOINT = os.environ.get("KRIPTIK_AI_ENDPOINT")
AI_API_KEY = os.environ.get("KRIPTIK_AI_API_KEY")


async def analyze_multimodal(
    text: Optional[str] = None,
    image_url: Optional[str] = None,
    audio_url: Optional[str] = None
) -> dict:
    """Analyze multimodal inputs using the deployed AI model."""
    async with httpx.AsyncClient() as client:
        response = await client.post(
            AI_ENDPOINT,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {AI_API_KEY}",
            },
            json={
                "text": text,
                "image_url": image_url,
                "audio_url": audio_url,
            },
            timeout=60.0,
        )
        response.raise_for_status()
        return response.json()
`,
    },
    flask: {
        llm: `
# AI Model Client - Generated by KripTik AI
import os
import requests

AI_ENDPOINT = os.environ.get("KRIPTIK_AI_ENDPOINT")
AI_API_KEY = os.environ.get("KRIPTIK_AI_API_KEY")


def generate_text(prompt: str, max_tokens: int = 1024, temperature: float = 0.7) -> dict:
    """Generate text using the deployed AI model."""
    response = requests.post(
        AI_ENDPOINT,
        headers={
            "Content-Type": "application/json",
            "Authorization": f"Bearer {AI_API_KEY}",
        },
        json={
            "prompt": prompt,
            "max_tokens": max_tokens,
            "temperature": temperature,
        },
        timeout=60,
    )
    response.raise_for_status()
    return response.json()
`,
        image: `
# AI Image Client - Generated by KripTik AI
import os
import requests
from typing import List

AI_ENDPOINT = os.environ.get("KRIPTIK_AI_ENDPOINT")
AI_API_KEY = os.environ.get("KRIPTIK_AI_API_KEY")


def generate_image(prompt: str, width: int = 1024, height: int = 1024, num_images: int = 1) -> List[str]:
    """Generate images using the deployed AI model."""
    response = requests.post(
        AI_ENDPOINT,
        headers={
            "Content-Type": "application/json",
            "Authorization": f"Bearer {AI_API_KEY}",
        },
        json={
            "prompt": prompt,
            "width": width,
            "height": height,
            "num_images": num_images,
        },
        timeout=120,
    )
    response.raise_for_status()
    return response.json().get("images", [])
`,
        video: `# AI Video Client - see fastapi template`,
        audio: `# AI Audio Client - see fastapi template`,
        multimodal: `# AI Multimodal Client - see fastapi template`,
    },
    django: {
        llm: `# AI LLM Client - see flask template`,
        image: `# AI Image Client - see flask template`,
        video: `# AI Video Client - see flask template`,
        audio: `# AI Audio Client - see flask template`,
        multimodal: `# AI Multimodal Client - see flask template`,
    },
    python: {
        llm: `# AI LLM Client - see flask template`,
        image: `# AI Image Client - see flask template`,
        video: `# AI Video Client - see flask template`,
        audio: `# AI Audio Client - see flask template`,
        multimodal: `# AI Multimodal Client - see flask template`,
    },
    other: {
        llm: `// Generic AI Client - adapt to your framework`,
        image: `// Generic AI Client - adapt to your framework`,
        video: `// Generic AI Client - adapt to your framework`,
        audio: `// Generic AI Client - adapt to your framework`,
        multimodal: `// Generic AI Client - adapt to your framework`,
    },
};

export class ModelWiringService {
    /**
     * Wire a deployed model to an external app
     */
    async wireModel(config: WiringConfig, app: ImportedApp): Promise<WiringResult> {
        const result: WiringResult = {
            id: uuidv4(),
            success: false,
            modifiedFiles: [],
            envVariables: {},
            instructions: '',
            warnings: [],
            rollbackAvailable: false,
        };

        try {
            // Find the integration point
            const integrationPoint = app.integrationPoints.find((p) => p.id === config.integrationPointId);
            if (!integrationPoint) {
                throw new Error(`Integration point not found: ${config.integrationPointId}`);
            }

            // Check model compatibility
            if (!integrationPoint.modelCompatibility.includes(config.modelType)) {
                result.warnings.push(
                    `Model type '${config.modelType}' may not be fully compatible with integration point '${integrationPoint.type}'`
                );
            }

            // Generate client code
            const clientCode = this.generateClientCode(app.framework, config.endpointUrl, config.modelType);

            // Determine where to place the client code
            const clientFilePath = this.getClientFilePath(app.framework, app.structure);

            // Create the client file modification
            result.modifiedFiles.push({
                path: clientFilePath,
                originalContent: '', // New file
                modifiedContent: clientCode,
                changes: ['Created AI client file'],
            });

            // Generate import statement for the integration point
            const importStatement = this.generateImportStatement(app.framework, clientFilePath, config.modelType);

            // Generate usage example for the integration point
            const usageExample = this.generateUsageExample(
                app.framework,
                integrationPoint.type,
                config.modelType
            );

            // Set up environment variables
            result.envVariables = {
                KRIPTIK_AI_ENDPOINT: config.endpointUrl,
                KRIPTIK_AI_API_KEY: config.apiKey || 'your-api-key-here',
            };

            // Adjust env var names for React
            if (app.framework === 'react') {
                result.envVariables = {
                    REACT_APP_KRIPTIK_AI_ENDPOINT: config.endpointUrl,
                    REACT_APP_KRIPTIK_AI_API_KEY: config.apiKey || 'your-api-key-here',
                };
            }

            // Generate instructions
            result.instructions = this.generateInstructions(
                app.framework,
                clientFilePath,
                integrationPoint,
                importStatement,
                usageExample,
                result.envVariables
            );

            result.success = true;
            result.rollbackAvailable = true;

            // Save wiring history
            await this.saveWiringHistory(config, result);

            return result;
        } catch (error) {
            result.success = false;
            result.instructions = `Error: ${error instanceof Error ? error.message : 'Unknown error'}`;
            return result;
        }
    }

    /**
     * Generate client code for a specific framework and model type
     */
    generateClientCode(
        framework: SupportedFramework,
        endpointUrl: string,
        modelType: ModelModality
    ): string {
        // Get base template
        let template = CODE_TEMPLATES[framework]?.[modelType] || CODE_TEMPLATES.other[modelType];

        // Replace placeholder with actual endpoint if provided
        if (endpointUrl && !endpointUrl.includes('process.env')) {
            // If a specific endpoint is provided, we can optionally hard-code it
            // But generally, we use environment variables
        }

        return template.trim();
    }

    /**
     * Preview wiring without applying changes
     */
    async previewWiring(config: WiringConfig, app: ImportedApp): Promise<WiringPreview> {
        const result = await this.wireModel(config, app);
        return {
            ...result,
            preview: true,
        };
    }

    /**
     * Apply wiring changes (for when we have filesystem access)
     * This is typically used in conjunction with GitHub push
     */
    async applyWiring(config: WiringConfig, app: ImportedApp): Promise<WiringResult> {
        const result = await this.wireModel(config, app);

        // In a full implementation, this would write files to a temporary directory
        // or prepare them for GitHub push

        return result;
    }

    /**
     * Get the appropriate path for the AI client file
     */
    private getClientFilePath(framework: SupportedFramework, structure: ImportedApp['structure']): string {
        const basePaths: Record<SupportedFramework, string> = {
            nextjs: `${structure.sourceDir || 'src'}/lib/ai-client.ts`,
            react: `${structure.sourceDir || 'src'}/utils/ai-client.ts`,
            express: 'lib/ai-client.js',
            nodejs: 'lib/ai-client.js',
            fastapi: 'app/services/ai_client.py',
            flask: 'app/services/ai_client.py',
            django: 'app/services/ai_client.py',
            python: 'ai_client.py',
            other: 'ai-client.js',
        };

        return basePaths[framework] || 'ai-client.js';
    }

    /**
     * Generate import statement for the client
     */
    private generateImportStatement(
        framework: SupportedFramework,
        clientFilePath: string,
        modelType: ModelModality
    ): string {
        const funcNames: Record<ModelModality, string> = {
            llm: 'generateText',
            image: 'generateImage',
            video: 'generateVideo',
            audio: 'generateAudio',
            multimodal: 'analyzeMultimodal',
        };

        const funcName = funcNames[modelType];
        const relativePath = clientFilePath.replace(/\.(ts|js|py)$/, '');

        if (framework.includes('python') || framework === 'fastapi' || framework === 'flask' || framework === 'django') {
            return `from ${relativePath.replace(/\//g, '.')} import ${funcName}`;
        }

        if (framework === 'nextjs' || framework === 'react') {
            return `import { ${funcName} } from '@/${relativePath}';`;
        }

        return `const { ${funcName} } = require('./${relativePath}');`;
    }

    /**
     * Generate usage example
     */
    private generateUsageExample(
        framework: SupportedFramework,
        integrationType: string,
        modelType: ModelModality
    ): string {
        const examples: Record<ModelModality, Record<string, string>> = {
            llm: {
                api_route_nextjs: `
// In your API route:
const result = await generateText(prompt);
return Response.json(result);
`,
                component_react: `
// In your component:
const { generate, loading, response } = useAIText();

const handleSubmit = async () => {
  const result = await generate(inputText);
  console.log(result);
};
`,
                api_route_express: `
// In your route handler:
const result = await generateText(req.body.prompt);
res.json(result);
`,
                api_route_fastapi: `
# In your route:
result = await generate_text(request.prompt)
return result
`,
            },
            image: {
                api_route_nextjs: `
// In your API route:
const images = await generateImage(prompt);
return Response.json({ images });
`,
                component_react: `
// In your component:
const { generate, loading, images } = useAIImage();

const handleGenerate = async () => {
  const result = await generate(prompt);
  setGeneratedImages(result);
};
`,
            },
            video: {
                api_route_nextjs: `
// In your API route:
const videoUrl = await generateVideo(prompt);
return Response.json({ videoUrl });
`,
            },
            audio: {
                api_route_nextjs: `
// In your API route:
const audioUrl = await generateAudio(text);
return Response.json({ audioUrl });
`,
            },
            multimodal: {
                api_route_nextjs: `
// In your API route:
const result = await analyzeMultimodal({ text, imageUrl });
return Response.json(result);
`,
            },
        };

        const frameworkType = `${integrationType}_${framework}`;
        return examples[modelType]?.[frameworkType] || examples[modelType]?.api_route_nextjs || '';
    }

    /**
     * Generate comprehensive instructions
     */
    private generateInstructions(
        framework: SupportedFramework,
        clientFilePath: string,
        integrationPoint: IntegrationPoint,
        importStatement: string,
        usageExample: string,
        envVariables: Record<string, string>
    ): string {
        const envInstructions = Object.entries(envVariables)
            .map(([key, value]) => `${key}=${value}`)
            .join('\n');

        return `
# KripTik AI Model Integration Instructions

## 1. Add the AI Client File
Create the file: \`${clientFilePath}\`
(Contents provided in the modified files section)

## 2. Add Environment Variables
Add these to your \`.env\` file:
\`\`\`
${envInstructions}
\`\`\`

## 3. Import the Client
Add this import to \`${integrationPoint.filePath}\`:
\`\`\`
${importStatement}
\`\`\`

## 4. Use the Client
At line ${integrationPoint.lineNumber} (${integrationPoint.description}):
\`\`\`
${usageExample}
\`\`\`

## 5. Install Dependencies (if needed)
${this.getDependencyInstructions(framework)}

## Notes
- The API key should be kept secret and not committed to version control
- Consider adding rate limiting for production use
- Test the integration in development before deploying
`.trim();
    }

    /**
     * Get dependency installation instructions
     */
    private getDependencyInstructions(framework: SupportedFramework): string {
        const instructions: Record<string, string> = {
            nextjs: 'No additional dependencies needed (fetch is built-in)',
            react: 'No additional dependencies needed (fetch is built-in)',
            express: 'No additional dependencies needed (node-fetch or built-in fetch in Node 18+)',
            nodejs: 'For Node < 18: `npm install node-fetch`',
            fastapi: '`pip install httpx`',
            flask: '`pip install requests`',
            django: '`pip install requests`',
            python: '`pip install requests`',
        };

        return instructions[framework] || 'Install appropriate HTTP client for your framework';
    }

    /**
     * Save wiring history to database
     */
    private async saveWiringHistory(config: WiringConfig, result: WiringResult): Promise<void> {
        try {
            const { appWiringHistory } = await import('../../schema.js');
            await db.insert(appWiringHistory).values({
                // id is auto-generated by $defaultFn
                appId: config.appId,
                deploymentId: config.deploymentId,
                integrationPointId: config.integrationPointId,
                endpointUrl: config.endpointUrl,
                modelType: config.modelType,
                success: result.success,
                modifiedFiles: result.modifiedFiles,
                envVariables: result.envVariables,
                instructions: result.instructions,
                createdAt: new Date().toISOString(),
            });
        } catch (error) {
            console.error('Failed to save wiring history:', error);
        }
    }
}

// Export singleton instance
let modelWiringInstance: ModelWiringService | null = null;

export function getModelWiringService(): ModelWiringService {
    if (!modelWiringInstance) {
        modelWiringInstance = new ModelWiringService();
    }
    return modelWiringInstance;
}
