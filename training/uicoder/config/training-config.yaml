# UICoder Training Configuration
# Fine-tunes Mistral-7B-Instruct for UI code generation

# Model Configuration
model:
  base_model: "mistralai/Mistral-7B-Instruct-v0.2"
  # Alternative: deepseek-ai/deepseek-coder-33b-instruct
  load_in_8bit: true
  device_map: "auto"

# LoRA Configuration
lora:
  r: 32                      # LoRA rank
  lora_alpha: 32             # LoRA alpha (usually equal to r)
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj
  lora_dropout: 0.05
  bias: "none"
  task_type: "CAUSAL_LM"

# Training Arguments
training:
  output_dir: "/workspace/uicoder_output"
  num_train_epochs: 5
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 0.00004      # 4e-5
  weight_decay: 0.01
  warmup_ratio: 0.03
  lr_scheduler_type: "cosine"
  max_grad_norm: 1.0

  # Logging
  logging_steps: 10
  save_steps: 500
  save_total_limit: 3

  # Optimization
  fp16: true
  gradient_checkpointing: true
  optim: "adamw_8bit"

  # Evaluation
  evaluation_strategy: "steps"
  eval_steps: 500

  # Other
  seed: 42
  dataloader_num_workers: 4
  remove_unused_columns: false
  report_to: "tensorboard"

# Dataset Configuration
dataset:
  train_file: "/workspace/uicoder/training-data.jsonl"
  max_seq_length: 4096
  packing: false

# Prompt Template
prompt_template: |
  <s>[INST] {instruction}

  {input} [/INST]
  {output}</s>

# Validation - Automated feedback loop
validation:
  # TypeScript compilation check
  typescript_check: true
  # VL-JEPA visual similarity (when screenshot available)
  visual_similarity_threshold: 0.85
  # Lighthouse performance check
  lighthouse_check: true
  lighthouse_min_score: 90

# Hardware Requirements
hardware:
  gpu: "NVIDIA A100 40GB"     # Larger model needs more VRAM
  vram_required: "40GB"
  estimated_time: "8-12 hours"
