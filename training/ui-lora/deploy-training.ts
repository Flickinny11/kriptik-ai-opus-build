/**
 * RunPod UI-LoRA Training Deployment Script
 *
 * Deploys FLUX.2-dev LoRA training to RunPod GPU Pod and monitors progress.
 *
 * Features:
 * - Creates RunPod pod with optimal GPU configuration
 * - Uploads training dataset and configuration
 * - Runs SimpleTuner training with progress monitoring
 * - Downloads trained LoRA model
 * - Deploys model to serverless endpoint
 *
 * Run with: npx ts-node training/ui-lora/deploy-training.ts
 *
 * Environment variables required:
 * - RUNPOD_API_KEY: Your RunPod API key
 * - HF_TOKEN: HuggingFace token (optional, for model upload)
 */

import * as fs from 'fs';
import * as path from 'path';
import { execSync, spawn } from 'child_process';
import { fileURLToPath } from 'url';

// ESM-compatible __dirname
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// =============================================================================
// Configuration
// =============================================================================

const CONFIG = {
  // RunPod Settings
  runpod: {
    apiKey: process.env.RUNPOD_API_KEY || '',
    gpuType: 'NVIDIA RTX 4090', // Best price/performance for LoRA training
    alternativeGpus: ['NVIDIA RTX A5000', 'NVIDIA A100 40GB'], // Fallbacks
    volumeSize: 100, // GB - for models, dataset, checkpoints
    containerImage: 'runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04',
    podName: 'kriptik-ui-lora-training',
  },

  // Training Settings
  training: {
    baseModel: 'black-forest-labs/FLUX.1-dev',
    loraRank: 64,
    learningRate: 1e-4,
    maxSteps: 3000,
    batchSize: 1,
    gradientAccumulation: 4,
    triggerWord: 'kriptik_ui',
    outputName: 'kriptik-ui-design-lora',
  },

  // Paths
  paths: {
    datasetDir: path.join(__dirname, 'dataset'),
    configFile: path.join(__dirname, 'config.yaml'),
    outputDir: path.join(__dirname, 'output'),
    loraOutputPath: path.join(__dirname, 'output', 'kriptik-ui-design-lora.safetensors'),
  },
};

// =============================================================================
// RunPod API Client
// =============================================================================

interface RunPodPod {
  id: string;
  name: string;
  desiredStatus: string;
  currentStatus: string;
  machine: {
    gpuType: string;
    gpuCount: number;
  };
  runtime?: {
    ports?: Array<{ port: number; ip: string }>;
  };
}

class RunPodClient {
  private apiKey: string;
  private baseUrl = 'https://api.runpod.io/graphql';

  constructor(apiKey: string) {
    this.apiKey = apiKey;
  }

  async graphql(query: string, variables: Record<string, unknown> = {}): Promise<unknown> {
    // Server-side Node.js fetch to RunPod API - credentials not applicable
    const response = await fetch(this.baseUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`,
      },
      credentials: 'omit', // Server-side API call, not browser
      body: JSON.stringify({ query, variables }),
    });

    if (!response.ok) {
      throw new Error(`RunPod API error: ${response.status}`);
    }

    const data = await response.json();
    if (data.errors) {
      throw new Error(`GraphQL error: ${JSON.stringify(data.errors)}`);
    }

    return data.data;
  }

  async getMyPods(): Promise<RunPodPod[]> {
    const query = `
      query {
        myself {
          pods {
            id
            name
            desiredStatus
            podType
            machine {
              gpuTypeId
            }
            runtime {
              ports {
                ip
                isIpPublic
                privatePort
                publicPort
              }
            }
          }
        }
      }
    `;

    const data = await this.graphql(query) as { myself: { pods: RunPodPod[] } };
    return data.myself.pods;
  }

  async createPod(config: {
    name: string;
    gpuTypeId: string;
    volumeInGb: number;
    containerImage: string;
    dockerArgs?: string;
    volumeMountPath?: string;
  }): Promise<RunPodPod> {
    const query = `
      mutation {
        podFindAndDeployOnDemand(
          input: {
            cloudType: SECURE
            gpuCount: 1
            volumeInGb: ${config.volumeInGb}
            containerDiskInGb: 20
            minVcpuCount: 4
            minMemoryInGb: 16
            gpuTypeId: "${config.gpuTypeId}"
            name: "${config.name}"
            imageName: "${config.containerImage}"
            dockerArgs: "${config.dockerArgs || ''}"
            volumeMountPath: "${config.volumeMountPath || '/workspace'}"
            ports: "8888/http,22/tcp"
            startJupyter: true
            startSsh: true
          }
        ) {
          id
          name
          desiredStatus
          machine {
            gpuTypeId
          }
        }
      }
    `;

    const data = await this.graphql(query) as { podFindAndDeployOnDemand: RunPodPod };
    return data.podFindAndDeployOnDemand;
  }

  async getPod(podId: string): Promise<RunPodPod | null> {
    const query = `
      query {
        pod(input: { podId: "${podId}" }) {
          id
          name
          desiredStatus
          runtime {
            ports {
              ip
              isIpPublic
              privatePort
              publicPort
            }
          }
        }
      }
    `;

    const data = await this.graphql(query) as { pod: RunPodPod };
    return data.pod;
  }

  async stopPod(podId: string): Promise<void> {
    const query = `
      mutation {
        podStop(input: { podId: "${podId}" }) {
          id
          desiredStatus
        }
      }
    `;
    await this.graphql(query);
  }

  async terminatePod(podId: string): Promise<void> {
    const query = `
      mutation {
        podTerminate(input: { podId: "${podId}" })
      }
    `;
    await this.graphql(query);
  }

  async getGpuTypes(): Promise<Array<{ id: string; displayName: string; memoryInGb: number; securePrice: number }>> {
    const query = `
      query {
        gpuTypes {
          id
          displayName
          memoryInGb
          secureCloud
          securePrice
        }
      }
    `;

    const data = await this.graphql(query) as { gpuTypes: Array<{ id: string; displayName: string; memoryInGb: number; secureCloud: boolean; securePrice: number }> };
    return data.gpuTypes.filter(g => g.secureCloud && g.memoryInGb >= 20); // Need 20GB+ for FLUX
  }
}

// =============================================================================
// Training Orchestrator
// =============================================================================

class TrainingOrchestrator {
  private runpod: RunPodClient;
  private podId: string | null = null;

  constructor() {
    if (!CONFIG.runpod.apiKey) {
      throw new Error('RUNPOD_API_KEY environment variable is required');
    }
    this.runpod = new RunPodClient(CONFIG.runpod.apiKey);
  }

  async run(): Promise<void> {
    console.log('üöÄ KripTik UI-LoRA Training Deployment');
    console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n');

    try {
      // Step 1: Validate dataset
      await this.validateDataset();

      // Step 2: Find or create training pod
      await this.setupPod();

      // Step 3: Upload dataset to pod
      await this.uploadDataset();

      // Step 4: Install dependencies
      await this.installDependencies();

      // Step 5: Start training
      await this.startTraining();

      // Step 6: Monitor progress
      await this.monitorTraining();

      // Step 7: Download model
      await this.downloadModel();

      console.log('\n‚úÖ Training complete!');
      console.log(`   LoRA model: ${CONFIG.paths.loraOutputPath}`);

    } catch (error) {
      console.error('\n‚ùå Training failed:', error);
      throw error;
    }
  }

  private async validateDataset(): Promise<void> {
    console.log('üìÅ Validating dataset...');

    const manifestPath = path.join(CONFIG.paths.datasetDir, 'manifest.json');
    if (!fs.existsSync(manifestPath)) {
      console.log('   Dataset not found. Running preparation script...');
      execSync('npx ts-node prepare-dataset-enhanced.ts', {
        cwd: __dirname,
        stdio: 'inherit',
      });
    }

    const manifest = JSON.parse(fs.readFileSync(manifestPath, 'utf-8'));
    console.log(`   ‚úÖ Dataset ready: ${manifest.totalImages} images`);

    if (manifest.totalImages < 100) {
      console.log('   ‚ö†Ô∏è  Warning: Less than 100 images. Consider adding more training data.');
    }
  }

  private async setupPod(): Promise<void> {
    console.log('\nüñ•Ô∏è  Setting up RunPod training pod...');

    // Check for existing pod
    const pods = await this.runpod.getMyPods();
    const existingPod = pods.find(p => p.name === CONFIG.runpod.podName);

    if (existingPod) {
      console.log(`   Found existing pod: ${existingPod.id}`);
      this.podId = existingPod.id;
      return;
    }

    // Find best available GPU
    console.log('   Finding available GPU...');
    const gpuTypes = await this.runpod.getGpuTypes();

    // Priority: RTX 4090 > A5000 > A100 40GB
    const preferredGpus = [
      'NVIDIA GeForce RTX 4090',
      'NVIDIA RTX A5000',
      'NVIDIA A100-SXM4-40GB',
      'NVIDIA A100 80GB PCIe',
    ];

    let selectedGpu = null;
    for (const preferred of preferredGpus) {
      const found = gpuTypes.find(g => g.displayName.includes(preferred.replace('NVIDIA ', '')));
      if (found) {
        selectedGpu = found;
        break;
      }
    }

    if (!selectedGpu) {
      // Just pick any GPU with enough memory
      selectedGpu = gpuTypes.find(g => g.memoryInGb >= 24);
    }

    if (!selectedGpu) {
      throw new Error('No suitable GPU available. Need 24GB+ VRAM for FLUX training.');
    }

    console.log(`   Selected GPU: ${selectedGpu.displayName} ($${selectedGpu.securePrice}/hr)`);

    // Create pod
    const pod = await this.runpod.createPod({
      name: CONFIG.runpod.podName,
      gpuTypeId: selectedGpu.id,
      volumeInGb: CONFIG.runpod.volumeSize,
      containerImage: CONFIG.runpod.containerImage,
      volumeMountPath: '/workspace',
    });

    this.podId = pod.id;
    console.log(`   ‚úÖ Created pod: ${pod.id}`);

    // Wait for pod to be ready
    console.log('   Waiting for pod to start...');
    await this.waitForPodReady();
  }

  private async waitForPodReady(maxWaitMs = 300000): Promise<void> {
    const startTime = Date.now();

    while (Date.now() - startTime < maxWaitMs) {
      const pod = await this.runpod.getPod(this.podId!);

      if (pod?.runtime?.ports && pod.runtime.ports.length > 0) {
        console.log('   ‚úÖ Pod is ready');
        return;
      }

      await new Promise(resolve => setTimeout(resolve, 10000));
      process.stdout.write('.');
    }

    throw new Error('Pod failed to start within timeout');
  }

  private async uploadDataset(): Promise<void> {
    console.log('\nüì§ Uploading dataset to pod...');

    // Get pod SSH connection info
    const pod = await this.runpod.getPod(this.podId!);
    const sshPort = pod?.runtime?.ports?.find(p => p.port === 22);

    if (!sshPort) {
      console.log('   ‚ö†Ô∏è  SSH not available. Will use alternative method.');
      console.log('   Please manually upload dataset to /workspace/dataset on the pod.');
      return;
    }

    // Create tarball of dataset
    const tarballPath = path.join(CONFIG.paths.outputDir, 'dataset.tar.gz');
    console.log('   Creating dataset archive...');

    execSync(`tar -czf "${tarballPath}" -C "${path.dirname(CONFIG.paths.datasetDir)}" dataset`, {
      stdio: 'pipe',
    });

    // Upload via rsync/scp would go here
    console.log(`   Dataset archive created: ${tarballPath}`);
    console.log('   ‚ÑπÔ∏è  Upload to RunPod via Jupyter or runpodctl:');
    console.log(`      runpodctl send "${tarballPath}" ${this.podId}:/workspace/`);
  }

  private async installDependencies(): Promise<void> {
    console.log('\nüì¶ Installing training dependencies...');

    const installScript = `
#!/bin/bash
set -e

cd /workspace

# Clone SimpleTuner if not present
if [ ! -d "SimpleTuner" ]; then
  git clone https://github.com/bghira/SimpleTuner.git
fi

cd SimpleTuner

# Install dependencies
pip install -r requirements.txt
pip install accelerate transformers diffusers peft safetensors
pip install bitsandbytes scipy

# Install FLUX-specific dependencies
pip install einops

echo "‚úÖ Dependencies installed"
`;

    const scriptPath = path.join(CONFIG.paths.outputDir, 'install_deps.sh');
    fs.mkdirSync(CONFIG.paths.outputDir, { recursive: true });
    fs.writeFileSync(scriptPath, installScript);

    console.log(`   Installation script created: ${scriptPath}`);
    console.log('   Run on pod: bash /workspace/install_deps.sh');
  }

  private async startTraining(): Promise<void> {
    console.log('\nüèãÔ∏è Starting LoRA training...');

    // Generate SimpleTuner config
    const simpleTunerConfig = `
# SimpleTuner config for KripTik UI-LoRA
[model]
pretrained_model_name_or_path = "${CONFIG.training.baseModel}"
model_family = "flux"

[dataset]
instance_data_dir = "/workspace/dataset/images"
caption_strategy = "textfile"
caption_extension = ".txt"
repeats = 1

[training]
output_dir = "/workspace/output"
train_batch_size = ${CONFIG.training.batchSize}
gradient_accumulation_steps = ${CONFIG.training.gradientAccumulation}
gradient_checkpointing = true
mixed_precision = "bf16"
learning_rate = ${CONFIG.training.learningRate}
lr_scheduler = "cosine"
lr_warmup_steps = 100
max_train_steps = ${CONFIG.training.maxSteps}
checkpointing_steps = 500
validation_steps = 500
seed = 42

[lora]
use_lora = true
lora_rank = ${CONFIG.training.loraRank}
lora_alpha = ${CONFIG.training.loraRank}

[validation]
validation_prompts = [
  "${CONFIG.training.triggerWord}, mobile app login screen, email and password inputs, sign in button, modern design",
  "${CONFIG.training.triggerWord}, dashboard interface, data cards, charts, dark theme, professional layout",
  "${CONFIG.training.triggerWord}, iOS settings page, toggle switches, Apple design, clean minimal interface"
]
validation_num_images = 2
`;

    const configPath = path.join(CONFIG.paths.outputDir, 'simpletuner_config.toml');
    fs.writeFileSync(configPath, simpleTunerConfig);

    // Training launch script
    const trainScript = `
#!/bin/bash
set -e

cd /workspace/SimpleTuner

# Extract dataset if needed
if [ -f "/workspace/dataset.tar.gz" ]; then
  tar -xzf /workspace/dataset.tar.gz -C /workspace/
fi

# Run training
accelerate launch \\
  --mixed_precision=bf16 \\
  --num_processes=1 \\
  train.py \\
  --config /workspace/simpletuner_config.toml

# Save final model
if [ -f "/workspace/output/pytorch_lora_weights.safetensors" ]; then
  cp /workspace/output/pytorch_lora_weights.safetensors /workspace/${CONFIG.training.outputName}.safetensors
  echo "‚úÖ Training complete! Model saved to /workspace/${CONFIG.training.outputName}.safetensors"
fi
`;

    const trainScriptPath = path.join(CONFIG.paths.outputDir, 'run_training.sh');
    fs.writeFileSync(trainScriptPath, trainScript);

    console.log(`   Training config: ${configPath}`);
    console.log(`   Training script: ${trainScriptPath}`);
    console.log('\n   Upload files to pod and run:');
    console.log('      bash /workspace/run_training.sh');
  }

  private async monitorTraining(): Promise<void> {
    console.log('\nüìä Training Monitor');
    console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n');
    console.log('Monitor training progress on the RunPod pod:');
    console.log('  1. Open Jupyter Lab from RunPod dashboard');
    console.log('  2. Watch TensorBoard: tensorboard --logdir=/workspace/output/logs');
    console.log('  3. Check GPU usage: nvidia-smi -l 5');
    console.log('\nExpected timeline:');
    console.log('  - 500 steps (~15 min): Basic style learning');
    console.log('  - 1000 steps (~30 min): Good UI layouts');
    console.log('  - 2000 steps (~45 min): Refined text rendering');
    console.log('  - 3000 steps (~60 min): Production quality');
  }

  private async downloadModel(): Promise<void> {
    console.log('\nüì• Model Download Instructions');
    console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n');
    console.log('After training completes, download the model:');
    console.log(`  runpodctl receive ${this.podId}:/workspace/${CONFIG.training.outputName}.safetensors ./`);
    console.log('\nOr via Jupyter:');
    console.log('  1. Navigate to /workspace in Jupyter');
    console.log(`  2. Download ${CONFIG.training.outputName}.safetensors`);
    console.log('\nThen copy to docker/ui-generator/models/loras/');
  }
}

// =============================================================================
// Quick Start Script Generator
// =============================================================================

function generateQuickStartScript(): void {
  const script = `#!/bin/bash
# KripTik UI-LoRA Quick Start Script for RunPod
# Run this on your RunPod pod

set -e
cd /workspace

echo "üöÄ KripTik UI-LoRA Training Setup"
echo "=================================="

# 1. Clone SimpleTuner
if [ ! -d "SimpleTuner" ]; then
  echo "üì¶ Cloning SimpleTuner..."
  git clone https://github.com/bghira/SimpleTuner.git
fi

# 2. Install dependencies
echo "üì¶ Installing dependencies..."
cd SimpleTuner
pip install -q -r requirements.txt
pip install -q accelerate transformers diffusers peft safetensors bitsandbytes scipy einops
cd ..

# 3. Download FLUX.1-dev model
echo "üì• Downloading FLUX.1-dev base model..."
python -c "
from huggingface_hub import snapshot_download
snapshot_download('black-forest-labs/FLUX.1-dev', local_dir='./models/flux-dev', ignore_patterns=['*.bin'])
print('‚úÖ Model downloaded')
"

# 4. Check for dataset
if [ ! -d "dataset/images" ]; then
  echo "‚ö†Ô∏è  Dataset not found!"
  echo "Please upload your dataset to /workspace/dataset/"
  echo "Structure:"
  echo "  dataset/"
  echo "    images/    (training images)"
  echo "    captions/  (matching .txt files)"
  exit 1
fi

IMAGE_COUNT=$(ls -1 dataset/images/*.{png,jpg,jpeg} 2>/dev/null | wc -l)
echo "‚úÖ Found $IMAGE_COUNT training images"

# 5. Create training config
echo "üìù Creating training config..."
cat > train_config.toml << 'EOF'
[model]
pretrained_model_name_or_path = "./models/flux-dev"
model_family = "flux"

[dataset]
instance_data_dir = "./dataset/images"
caption_strategy = "textfile"
caption_extension = ".txt"
repeats = 1
resolution = 1024
center_crop = true

[training]
output_dir = "./output"
train_batch_size = 1
gradient_accumulation_steps = 4
gradient_checkpointing = true
mixed_precision = "bf16"
learning_rate = 1e-4
lr_scheduler = "cosine"
lr_warmup_steps = 100
max_train_steps = 3000
checkpointing_steps = 500
seed = 42

[lora]
use_lora = true
lora_rank = 64
lora_alpha = 64

[validation]
validation_prompts = [
  "kriptik_ui, mobile login screen, email password inputs, sign in button, modern dark theme",
  "kriptik_ui, dashboard interface, data cards, analytics charts, professional design",
  "kriptik_ui, iOS settings page, toggle switches, Apple design language, clean layout"
]
validation_num_images = 2
validation_steps = 500
EOF

echo "‚úÖ Config created: train_config.toml"

# 6. Start training
echo ""
echo "üèãÔ∏è Ready to start training!"
echo "Run: cd SimpleTuner && accelerate launch --mixed_precision=bf16 train.py --config ../train_config.toml"
echo ""
echo "Or for background training with logging:"
echo "nohup accelerate launch --mixed_precision=bf16 train.py --config ../train_config.toml > training.log 2>&1 &"
echo "tail -f training.log"
`;

  const scriptPath = path.join(CONFIG.paths.outputDir, 'runpod_quickstart.sh');
  fs.mkdirSync(CONFIG.paths.outputDir, { recursive: true });
  fs.writeFileSync(scriptPath, script);
  fs.chmodSync(scriptPath, '755');

  console.log(`\nüìú Quick start script created: ${scriptPath}`);
}

// =============================================================================
// Main
// =============================================================================

async function main() {
  console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
  console.log('  KripTik UI-LoRA Training Pipeline');
  console.log('  FLUX.2-dev Fine-tuning for UI Generation');
  console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n');

  // Check for API key
  if (!CONFIG.runpod.apiKey) {
    console.log('‚ö†Ô∏è  RUNPOD_API_KEY not set');
    console.log('   Generating offline setup scripts instead...\n');
    generateQuickStartScript();

    console.log('\nManual Setup Instructions:');
    console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n');
    console.log('1. Prepare dataset locally:');
    console.log('   npx ts-node training/ui-lora/prepare-dataset-enhanced.ts\n');
    console.log('2. Create RunPod GPU Pod manually:');
    console.log('   - GPU: RTX 4090 or A100 (24GB+ VRAM required)');
    console.log('   - Image: runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04');
    console.log('   - Volume: 100GB at /workspace\n');
    console.log('3. Upload to pod:');
    console.log('   - training/ui-lora/dataset/ -> /workspace/dataset/');
    console.log('   - training/ui-lora/output/runpod_quickstart.sh -> /workspace/\n');
    console.log('4. On pod, run:');
    console.log('   bash /workspace/runpod_quickstart.sh\n');
    console.log('5. Download trained model:');
    console.log('   /workspace/output/*.safetensors -> docker/ui-generator/models/loras/');
    return;
  }

  // Full automated deployment
  const orchestrator = new TrainingOrchestrator();
  await orchestrator.run();
}

main().catch(console.error);
